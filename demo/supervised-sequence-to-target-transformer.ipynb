{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03a90ff7",
   "metadata": {},
   "source": [
    "# Supervised task with transformer sequence encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64030fe",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a258bf97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  239M  100  239M    0     0  52.2M      0  0:00:04  0:00:04 --:--:-- 54.1M\n",
      "Archive:  age-prediction-nti-sbebank-2019.zip\n",
      "  inflating: data/test.csv           \n",
      "  inflating: data/small_group_description.csv  \n",
      "  inflating: data/train_target.csv   \n",
      "  inflating: data/transactions_train.csv  \n",
      "  inflating: data/transactions_test.csv  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('data/transactions_train.csv'):\n",
    "    ! mkdir -p data\n",
    "    ! curl -OL https://storage.yandexcloud.net/ptls-datasets/age-prediction-nti-sbebank-2019.zip\n",
    "    ! unzip -j -o age-prediction-nti-sbebank-2019.zip 'data/*.csv' -d data\n",
    "    ! mv age-prediction-nti-sbebank-2019.zip data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862a9986",
   "metadata": {},
   "source": [
    "## Prepare your data\n",
    "\n",
    "- Use `Pyspark` in local or cluster mode for big dataset and `Pandas` for small.\n",
    "- Split data into required parts (train, valid, test, ...).\n",
    "- Use `ptls.preprocessing` for simple data preparation. \n",
    "- Transform features to compatible format using `Pyspark` or `Pandas` functions. \n",
    "You can also use `ptls.data_load.preprocessing` for common data transformation patterns.\n",
    "- Split sequences to `ptls-data` format with `ptls.data_load.split_tools`. Save prepared data into `Parquet` format or \n",
    "keep it in memory (`Pickle` also works).\n",
    "- Use one of the available `ptls.data_load.datasets` to define input for the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2bbf594a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: pytorch-lightning 1.6.5 has a non-standard dependency specifier torch>=1.8.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a000f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jupyterlab==4.0.0\n",
      "  Downloading jupyterlab-4.0.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /home/user/conda/lib/python3.9/site-packages (from jupyterlab==4.0.0) (2.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.3 in /home/user/conda/lib/python3.9/site-packages (from jupyterlab==4.0.0) (6.8.0)\n",
      "Requirement already satisfied: ipykernel in /home/user/conda/lib/python3.9/site-packages (from jupyterlab==4.0.0) (6.26.0)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /home/user/conda/lib/python3.9/site-packages (from jupyterlab==4.0.0) (3.1.2)\n",
      "Requirement already satisfied: jupyter-core in /home/user/conda/lib/python3.9/site-packages (from jupyterlab==4.0.0) (5.5.0)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /home/user/conda/lib/python3.9/site-packages (from jupyterlab==4.0.0) (2.2.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /home/user/conda/lib/python3.9/site-packages (from jupyterlab==4.0.0) (2.10.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.19.0 in /home/user/conda/lib/python3.9/site-packages (from jupyterlab==4.0.0) (2.25.1)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /home/user/conda/lib/python3.9/site-packages (from jupyterlab==4.0.0) (0.2.3)\n",
      "Requirement already satisfied: packaging in /home/user/conda/lib/python3.9/site-packages (from jupyterlab==4.0.0) (23.2)\n",
      "Requirement already satisfied: tomli in /home/user/conda/lib/python3.9/site-packages (from jupyterlab==4.0.0) (2.0.1)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /home/user/conda/lib/python3.9/site-packages (from jupyterlab==4.0.0) (6.2)\n",
      "Requirement already satisfied: traitlets in /home/user/conda/lib/python3.9/site-packages (from jupyterlab==4.0.0) (5.13.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/user/conda/lib/python3.9/site-packages (from async-lru>=1.0.0->jupyterlab==4.0.0) (4.8.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/user/conda/lib/python3.9/site-packages (from importlib-metadata>=4.8.3->jupyterlab==4.0.0) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/user/conda/lib/python3.9/site-packages (from jinja2>=3.0.3->jupyterlab==4.0.0) (2.1.3)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /home/user/conda/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (4.0.0)\n",
      "Requirement already satisfied: argon2-cffi in /home/user/conda/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (23.1.0)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in /home/user/conda/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (7.4.9)\n",
      "Requirement already satisfied: jupyter-events>=0.6.0 in /home/user/conda/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (0.9.0)\n",
      "Requirement already satisfied: jupyter-server-terminals in /home/user/conda/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (0.4.4)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in /home/user/conda/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (7.9.2)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /home/user/conda/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (5.9.2)\n",
      "Requirement already satisfied: overrides in /home/user/conda/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (7.4.0)\n",
      "Requirement already satisfied: prometheus-client in /home/user/conda/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (0.18.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /home/user/conda/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (24.0.1)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /home/user/conda/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/user/conda/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (0.18.0)\n",
      "Requirement already satisfied: websocket-client in /home/user/conda/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (1.6.4)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/user/conda/lib/python3.9/site-packages (from jupyter-core->jupyterlab==4.0.0) (4.0.0)\n",
      "Requirement already satisfied: babel>=2.10 in /home/user/conda/lib/python3.9/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab==4.0.0) (2.13.1)\n",
      "Requirement already satisfied: json5>=0.9.0 in /home/user/conda/lib/python3.9/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab==4.0.0) (0.9.14)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /home/user/conda/lib/python3.9/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab==4.0.0) (4.19.2)\n",
      "Requirement already satisfied: requests>=2.31 in /home/user/conda/lib/python3.9/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab==4.0.0) (2.31.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in /home/user/conda/lib/python3.9/site-packages (from ipykernel->jupyterlab==4.0.0) (0.1.4)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /home/user/conda/lib/python3.9/site-packages (from ipykernel->jupyterlab==4.0.0) (1.8.0)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /home/user/conda/lib/python3.9/site-packages (from ipykernel->jupyterlab==4.0.0) (8.17.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /home/user/conda/lib/python3.9/site-packages (from ipykernel->jupyterlab==4.0.0) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in /home/user/conda/lib/python3.9/site-packages (from ipykernel->jupyterlab==4.0.0) (1.5.8)\n",
      "Requirement already satisfied: psutil in /home/user/conda/lib/python3.9/site-packages (from ipykernel->jupyterlab==4.0.0) (5.9.5)\n",
      "Requirement already satisfied: idna>=2.8 in /home/user/conda/lib/python3.9/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/user/conda/lib/python3.9/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/user/conda/lib/python3.9/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (1.1.3)\n",
      "Requirement already satisfied: decorator in /home/user/conda/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyterlab==4.0.0) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/user/conda/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyterlab==4.0.0) (0.17.2)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /home/user/conda/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyterlab==4.0.0) (3.0.41)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/user/conda/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyterlab==4.0.0) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /home/user/conda/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyterlab==4.0.0) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/user/conda/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyterlab==4.0.0) (4.8.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/user/conda/lib/python3.9/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab==4.0.0) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/user/conda/lib/python3.9/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab==4.0.0) (2023.11.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/user/conda/lib/python3.9/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab==4.0.0) (0.31.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/user/conda/lib/python3.9/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab==4.0.0) (0.12.0)\n",
      "Requirement already satisfied: entrypoints in /home/user/conda/lib/python3.9/site-packages (from jupyter-client>=7.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/user/conda/lib/python3.9/site-packages (from jupyter-client>=7.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (2.8.2)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /home/user/conda/lib/python3.9/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /home/user/conda/lib/python3.9/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (6.0.1)\n",
      "Requirement already satisfied: rfc3339-validator in /home/user/conda/lib/python3.9/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /home/user/conda/lib/python3.9/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (0.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/user/conda/lib/python3.9/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (4.12.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /home/user/conda/lib/python3.9/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in /home/user/conda/lib/python3.9/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/user/conda/lib/python3.9/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (0.2.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /home/user/conda/lib/python3.9/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /home/user/conda/lib/python3.9/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (0.9.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/user/conda/lib/python3.9/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /home/user/conda/lib/python3.9/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (1.2.1)\n",
      "Requirement already satisfied: fastjsonschema in /home/user/conda/lib/python3.9/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (2.19.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/user/conda/lib/python3.9/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.19.0->jupyterlab==4.0.0) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/user/conda/lib/python3.9/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.19.0->jupyterlab==4.0.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user/conda/lib/python3.9/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.19.0->jupyterlab==4.0.0) (2023.7.22)\n",
      "Requirement already satisfied: ptyprocess in /home/user/conda/lib/python3.9/site-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /home/user/conda/lib/python3.9/site-packages (from argon2-cffi->jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (21.2.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/user/conda/lib/python3.9/site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /home/user/conda/lib/python3.9/site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (0.5.1)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /home/user/conda/lib/python3.9/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyterlab==4.0.0) (0.7.1)\n",
      "Requirement already satisfied: fqdn in /home/user/conda/lib/python3.9/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /home/user/conda/lib/python3.9/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /home/user/conda/lib/python3.9/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (2.4)\n",
      "Requirement already satisfied: uri-template in /home/user/conda/lib/python3.9/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in /home/user/conda/lib/python3.9/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (1.13)\n",
      "Requirement already satisfied: wcwidth in /home/user/conda/lib/python3.9/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=7.23.1->ipykernel->jupyterlab==4.0.0) (0.2.10)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /home/user/conda/lib/python3.9/site-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/user/conda/lib/python3.9/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (2.5)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/user/conda/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyterlab==4.0.0) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/user/conda/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyterlab==4.0.0) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /home/user/conda/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyterlab==4.0.0) (0.2.2)\n",
      "Requirement already satisfied: pycparser in /home/user/conda/lib/python3.9/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (2.21)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /home/user/conda/lib/python3.9/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /home/user/conda/lib/python3.9/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab==4.0.0) (2.8.19.14)\n",
      "Downloading jupyterlab-4.0.0-py3-none-any.whl (9.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mDEPRECATION: pytorch-lightning 1.6.5 has a non-standard dependency specifier torch>=1.8.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: jupyterlab\n",
      "  Attempting uninstall: jupyterlab\n",
      "    Found existing installation: jupyterlab 3.6.6\n",
      "    Uninstalling jupyterlab-3.6.6:\n",
      "      Successfully uninstalled jupyterlab-3.6.6\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ipydrawio 1.3.0 requires jupyterlab==3.*, but you have jupyterlab 4.0.0 which is incompatible.\n",
      "jupyterlab-interactive-dashboard-editor 0.4.0 requires jupyterlab~=3.0, but you have jupyterlab 4.0.0 which is incompatible.\n",
      "jupyterlab-lsp 5.0.0 requires jupyterlab<5.0.0a0,>=4.0.6, but you have jupyterlab 4.0.0 which is incompatible.\n",
      "jupyterlab-system-monitor 0.8.0 requires jupyterlab~=3.0, but you have jupyterlab 4.0.0 which is incompatible.\n",
      "jupyterlab-topbar 0.6.1 requires jupyterlab~=3.0, but you have jupyterlab 4.0.0 which is incompatible.\n",
      "lckr-jupyterlab-variableinspector 3.0.9 requires jupyterlab==3.*,>=3.0.0rc13, but you have jupyterlab 4.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed jupyterlab-4.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -q jupyterlab==4.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13e49f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-lifestream in /home/user/conda/lib/python3.9/site-packages (0.5.3)\n",
      "Requirement already satisfied: pytorch-lightning==1.6.* in /home/user/conda/lib/python3.9/site-packages (from pytorch-lifestream) (1.6.5)\n",
      "Requirement already satisfied: torch==1.12.* in /home/user/conda/lib/python3.9/site-packages (from pytorch-lifestream) (1.12.1)\n",
      "Requirement already satisfied: numpy==1.23.* in /home/user/conda/lib/python3.9/site-packages (from pytorch-lifestream) (1.23.5)\n",
      "Requirement already satisfied: torchmetrics==0.9.* in /home/user/conda/lib/python3.9/site-packages (from pytorch-lifestream) (0.9.3)\n",
      "Requirement already satisfied: omegaconf in /home/user/conda/lib/python3.9/site-packages (from pytorch-lifestream) (2.3.0)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /home/user/conda/lib/python3.9/site-packages (from pytorch-lightning==1.6.*->pytorch-lifestream) (4.66.1)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /home/user/conda/lib/python3.9/site-packages (from pytorch-lightning==1.6.*->pytorch-lifestream) (6.0.1)\n",
      "Requirement already satisfied: fsspec!=2021.06.0,>=2021.05.0 in /home/user/conda/lib/python3.9/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->pytorch-lifestream) (2023.10.0)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /home/user/conda/lib/python3.9/site-packages (from pytorch-lightning==1.6.*->pytorch-lifestream) (2.15.0)\n",
      "Requirement already satisfied: pyDeprecate>=0.3.1 in /home/user/conda/lib/python3.9/site-packages (from pytorch-lightning==1.6.*->pytorch-lifestream) (0.3.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/user/conda/lib/python3.9/site-packages (from pytorch-lightning==1.6.*->pytorch-lifestream) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/user/conda/lib/python3.9/site-packages (from pytorch-lightning==1.6.*->pytorch-lifestream) (4.8.0)\n",
      "Requirement already satisfied: protobuf<=3.20.1 in /home/user/conda/lib/python3.9/site-packages (from pytorch-lightning==1.6.*->pytorch-lifestream) (3.20.1)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /home/user/conda/lib/python3.9/site-packages (from omegaconf->pytorch-lifestream) (4.9.3)\n",
      "Requirement already satisfied: requests in /home/user/conda/lib/python3.9/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->pytorch-lifestream) (2.31.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/user/conda/lib/python3.9/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->pytorch-lifestream) (3.8.6)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/user/conda/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (2.0.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/user/conda/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (1.59.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/user/conda/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /home/user/conda/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (1.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/user/conda/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (3.5.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/user/conda/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (68.2.2)\n",
      "Requirement already satisfied: six>1.9 in /home/user/conda/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/user/conda/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/user/conda/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (3.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/user/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->pytorch-lifestream) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/user/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->pytorch-lifestream) (3.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/user/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->pytorch-lifestream) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/user/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->pytorch-lifestream) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/user/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->pytorch-lifestream) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/user/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->pytorch-lifestream) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/user/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->pytorch-lifestream) (1.3.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/user/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/user/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/user/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/user/conda/lib/python3.9/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/user/conda/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (6.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/user/conda/lib/python3.9/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->pytorch-lifestream) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/user/conda/lib/python3.9/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->pytorch-lifestream) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user/conda/lib/python3.9/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->pytorch-lifestream) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/user/conda/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/user/conda/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (3.17.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/user/conda/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/user/conda/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (3.2.2)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.6.5 has a non-standard dependency specifier torch>=1.8.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q pytorch-lifestream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "886d6a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting duckdb\n",
      "  Downloading duckdb-0.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (760 bytes)\n",
      "Downloading duckdb-0.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mDEPRECATION: pytorch-lightning 1.6.5 has a non-standard dependency specifier torch>=1.8.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: duckdb\n",
      "Successfully installed duckdb-0.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -q duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b93105f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.37.2-py3-none-any.whl.metadata (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m777.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/user/conda/lib/python3.9/site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n",
      "  Downloading huggingface_hub-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/user/conda/lib/python3.9/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/user/conda/lib/python3.9/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/user/conda/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2023.12.25-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m790.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/user/conda/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
      "  Downloading tokenizers-0.15.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/user/conda/lib/python3.9/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/user/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/user/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/user/conda/lib/python3.9/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/user/conda/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/user/conda/lib/python3.9/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user/conda/lib/python3.9/site-packages (from requests->transformers) (2023.7.22)\n",
      "Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.12.25-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m773.4/773.4 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mDEPRECATION: pytorch-lightning 1.6.5 has a non-standard dependency specifier torch>=1.8.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.20.3 regex-2023.12.25 safetensors-0.4.2 tokenizers-0.15.1 transformers-4.37.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bb3ccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from ptls.preprocessing import PandasDataPreprocessor\n",
    "from ptls.data_load.datasets import MemoryMapDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a795c9",
   "metadata": {},
   "source": [
    "Read target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a0303dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>bins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24662</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1046</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34089</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34848</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47076</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   client_id  bins\n",
       "0      24662     2\n",
       "1       1046     0\n",
       "2      34089     2\n",
       "3      34848     1\n",
       "4      47076     3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target = pd.read_csv('data/train_target.csv')\n",
    "df_target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208a2e4f",
   "metadata": {},
   "source": [
    "Split target data into train, test and validatation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cc01e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 30000 records to train: 20000, valid: 3000, test: 7000\n"
     ]
    }
   ],
   "source": [
    "df_target_train, df_target_test = train_test_split(\n",
    "    df_target, test_size=7000, stratify=df_target['bins'], random_state=142)\n",
    "df_target_train, df_target_valid = train_test_split(\n",
    "    df_target_train, test_size=3000, stratify=df_target_train['bins'], random_state=142)\n",
    "print('Split {} records to train: {}, valid: {}, test: {}'.format(\n",
    "    *[len(df) for df in [df_target, df_target_train, df_target_valid, df_target_test]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100c554c",
   "metadata": {},
   "source": [
    "Load data with transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2146a1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>trans_date</th>\n",
       "      <th>small_group</th>\n",
       "      <th>amount_rur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33172</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>71.463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33172</td>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "      <td>45.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33172</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>13.887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33172</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>15.983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33172</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>21.341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   client_id  trans_date  small_group  amount_rur\n",
       "0      33172           6            4      71.463\n",
       "1      33172           6           35      45.017\n",
       "2      33172           8           11      13.887\n",
       "3      33172           9           11      15.983\n",
       "4      33172          10           11      21.341"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trx = pd.read_csv('data/transactions_train.csv')\n",
    "df_trx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01f61caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 26450577 transactions to train: 17622321, valid: 2634248, test: 6194008\n"
     ]
    }
   ],
   "source": [
    "df_trx_train = pd.merge(df_trx, df_target_train['client_id'], on='client_id', how='inner')\n",
    "df_trx_valid = pd.merge(df_trx, df_target_valid['client_id'], on='client_id', how='inner')\n",
    "df_trx_test = pd.merge(df_trx, df_target_test['client_id'], on='client_id', how='inner')\n",
    "print('Split {} transactions to train: {}, valid: {}, test: {}'.format(\n",
    "    *[len(df) for df in [df_trx, df_trx_train, df_trx_valid, df_trx_test]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "37bfd82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>trans_date</th>\n",
       "      <th>small_group</th>\n",
       "      <th>amount_rur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4159434</th>\n",
       "      <td>42191</td>\n",
       "      <td>308</td>\n",
       "      <td>2</td>\n",
       "      <td>76.361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10477921</th>\n",
       "      <td>30412</td>\n",
       "      <td>628</td>\n",
       "      <td>11</td>\n",
       "      <td>20.237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2682069</th>\n",
       "      <td>1095</td>\n",
       "      <td>353</td>\n",
       "      <td>1</td>\n",
       "      <td>64.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10469276</th>\n",
       "      <td>20216</td>\n",
       "      <td>160</td>\n",
       "      <td>91</td>\n",
       "      <td>14.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4149024</th>\n",
       "      <td>48112</td>\n",
       "      <td>580</td>\n",
       "      <td>3</td>\n",
       "      <td>4.579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          client_id  trans_date  small_group  amount_rur\n",
       "4159434       42191         308            2      76.361\n",
       "10477921      30412         628           11      20.237\n",
       "2682069        1095         353            1      64.957\n",
       "10469276      20216         160           91      14.234\n",
       "4149024       48112         580            3       4.579"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trx_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11aa0d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform flat table to dictionaries with client features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "129f938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptls.preprocessing import PandasDataPreprocessor\n",
    "\n",
    "preprocessor = PandasDataPreprocessor(\n",
    "    col_id='client_id',\n",
    "    col_event_time='trans_date',\n",
    "    event_time_transformation='none',\n",
    "    cols_category=['small_group'],\n",
    "    cols_numerical=['amount_rur'],\n",
    "    return_records=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b4f6f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.2 s, sys: 6.14 s, total: 36.3 s\n",
      "Wall time: 36.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_data_train = preprocessor.fit_transform(df_trx_train)\n",
    "df_data_valid = preprocessor.transform(df_trx_valid)\n",
    "df_data_test = preprocessor.transform(df_trx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf17bf2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record in dataset, train 20000, valid 3000, test 7000\n",
      "Each record is a client with list of transactions\n"
     ]
    }
   ],
   "source": [
    "print('Record in dataset, train {}, valid {}, test {}\\nEach record is a client with list of transactions'.format(\n",
    "    *[len(df) for df in [df_data_train, df_data_valid, df_data_test]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b48cca65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>trans_date</th>\n",
       "      <th>event_time</th>\n",
       "      <th>small_group</th>\n",
       "      <th>amount_rur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>[tensor(0), tensor(5), tensor(10), tensor(11),...</td>\n",
       "      <td>[tensor(0), tensor(5), tensor(10), tensor(11),...</td>\n",
       "      <td>[tensor(4), tensor(3), tensor(1), tensor(3), t...</td>\n",
       "      <td>[tensor(4.0540, dtype=torch.float64), tensor(1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>[tensor(1), tensor(2), tensor(12), tensor(13),...</td>\n",
       "      <td>[tensor(1), tensor(2), tensor(12), tensor(13),...</td>\n",
       "      <td>[tensor(3), tensor(53), tensor(1), tensor(5), ...</td>\n",
       "      <td>[tensor(18.3190, dtype=torch.float64), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>[tensor(3), tensor(6), tensor(6), tensor(6), t...</td>\n",
       "      <td>[tensor(3), tensor(6), tensor(6), tensor(6), t...</td>\n",
       "      <td>[tensor(1), tensor(19), tensor(13), tensor(6),...</td>\n",
       "      <td>[tensor(3.0220, dtype=torch.float64), tensor(2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   client_id                                         trans_date  \\\n",
       "0          6  [tensor(0), tensor(5), tensor(10), tensor(11),...   \n",
       "1          7  [tensor(1), tensor(2), tensor(12), tensor(13),...   \n",
       "2         12  [tensor(3), tensor(6), tensor(6), tensor(6), t...   \n",
       "\n",
       "                                          event_time  \\\n",
       "0  [tensor(0), tensor(5), tensor(10), tensor(11),...   \n",
       "1  [tensor(1), tensor(2), tensor(12), tensor(13),...   \n",
       "2  [tensor(3), tensor(6), tensor(6), tensor(6), t...   \n",
       "\n",
       "                                         small_group  \\\n",
       "0  [tensor(4), tensor(3), tensor(1), tensor(3), t...   \n",
       "1  [tensor(3), tensor(53), tensor(1), tensor(5), ...   \n",
       "2  [tensor(1), tensor(19), tensor(13), tensor(6),...   \n",
       "\n",
       "                                          amount_rur  \n",
       "0  [tensor(4.0540, dtype=torch.float64), tensor(1...  \n",
       "1  [tensor(18.3190, dtype=torch.float64), tensor(...  \n",
       "2  [tensor(3.0220, dtype=torch.float64), tensor(2...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94e90b5",
   "metadata": {},
   "source": [
    "To learn our model, we need to add prefix target to target column due to feature naming rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f10d9339",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = df_target.rename(columns={'bins': 'target_bin'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e9d418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_train = pd.merge(df_data_train, df_target, on='client_id')\n",
    "df_data_valid = pd.merge(df_data_valid, df_target, on='client_id')\n",
    "df_data_test = pd.merge(df_data_test, df_target, on='client_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "baf6c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_train = df_data_train.to_dict(orient='records')\n",
    "df_data_valid = df_data_valid.to_dict(orient='records')\n",
    "df_data_test = df_data_test.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5c2ed62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'client_id': 6,\n",
       " 'trans_date': tensor([ 0,  5, 10, 11, 15, 15, 16, 16, 17, 18]),\n",
       " 'small_group': tensor([ 4,  3,  1,  3,  4,  1,  4,  3, 18,  2]),\n",
       " 'amount_rur': tensor([ 4.0540, 13.7380, 20.7010, 21.5640, 13.4990, 23.7220,  4.3040,  8.6250,\n",
       "         12.9380, 28.1620], dtype=torch.float64),\n",
       " 'event_time': tensor([ 0,  5, 10, 11, 15, 15, 16, 16, 17, 18]),\n",
       " 'target_bin': 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show first 10 transactions from one record\n",
    "rec = df_data_train[0]\n",
    "{k: v[:10] if type(v) is torch.Tensor else v for k, v in rec.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee05b02",
   "metadata": {},
   "source": [
    "Memory map dataset is a torch dataset, but also use filters to preprocess our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb94744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = MemoryMapDataset(df_data_train)\n",
    "dataset_valid = MemoryMapDataset(df_data_valid)\n",
    "dataset_test = MemoryMapDataset(df_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01d06ea",
   "metadata": {},
   "source": [
    "## Build encoder\n",
    "\n",
    "- All parts are available in `ptls.nn`.\n",
    "- You can also use pretrained layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f18d3ff",
   "metadata": {},
   "source": [
    "In this task we will use TransformerSeqEncoder based on transformer architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd9840d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "from ptls.nn import TrxEncoder, TransformerSeqEncoder, Head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4da826f",
   "metadata": {},
   "source": [
    "Define TrxEncoder to learn embedding for single transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d228aea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trx_encoder=TrxEncoder(\n",
    "        embeddings={\n",
    "            'small_group': {'in': 150, 'out': 31},\n",
    "        },\n",
    "        numeric_values={\n",
    "            'amount_rur': 'log',\n",
    "        },\n",
    "        embeddings_noise=0.001\n",
    ")\n",
    "\n",
    "trx_encoder.output_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62612d81",
   "metadata": {},
   "source": [
    "We can choose parameters for our transformer encoder, for example the number of heads in the multiheadattention, the number of sub-encoder-layers in the encoder and dimension of linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a594a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_params = {\n",
    "    \"n_heads\": 1,\n",
    "    \"dim_hidden\": 128,\n",
    "    \"n_layers\": 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d819703",
   "metadata": {},
   "source": [
    "Define sequence encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d51e5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_encoder = TransformerSeqEncoder(\n",
    "    trx_encoder=trx_encoder,\n",
    "    **transformer_params\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cc5f19",
   "metadata": {},
   "source": [
    "## Choose framework for encoder train\n",
    "\n",
    "- There are both supervised of unsupervised frameworks in `ptls.frames`.\n",
    "- Keep in mind that each framework requires his own batch format.\n",
    "Tools for batch collate can be found in the selected framework package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "34e999a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/conda/lib/python3.9/site-packages/pydantic/_internal/_fields.py:149: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/user/conda/lib/python3.9/site-packages/pydantic/_internal/_config.py:318: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from ptls.frames.supervised import SeqToTargetDataset, SequenceToTarget\n",
    "from ptls.frames import PtlsDataModule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bc2956",
   "metadata": {},
   "source": [
    "To define a model for supervised learning, we need sequence encoder to get embedding for one user, head to transform embeddings to solve our task. In this task we will use linear layer and softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3c661043",
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_module = SequenceToTarget(\n",
    "    seq_encoder=seq_encoder,\n",
    "    head=Head(input_size=seq_encoder.embedding_size, objective='classification', num_classes=4),\n",
    "    loss=torch.nn.NLLLoss(),\n",
    "    metric_list=torchmetrics.Accuracy(),\n",
    "    optimizer_partial=partial(torch.optim.Adam),\n",
    "    lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=4, gamma=0.5),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec49aef3",
   "metadata": {},
   "source": [
    "Data module to define data for training, validating and testing, batch sizes and number of workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "953afcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_data = PtlsDataModule(\n",
    "    train_data=SeqToTargetDataset(dataset_train, target_col_name='target_bin', target_dtype=torch.long),\n",
    "    valid_data=SeqToTargetDataset(dataset_valid, target_col_name='target_bin', target_dtype=torch.long),\n",
    "    test_data=SeqToTargetDataset(dataset_test, target_col_name='target_bin', target_dtype=torch.long),\n",
    "    train_batch_size=128,\n",
    "    valid_batch_size=1024,\n",
    "    train_num_workers=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a780c4",
   "metadata": {},
   "source": [
    "## Train your encoder with selected framework and `pytorch_lightning`\n",
    "\n",
    "- Provide data with one of the DataLoaders that is compatible with selected framework. \n",
    "- Monitor the progress on tensorboard.\n",
    "- Optionally tune hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "353ac8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2dca56e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b2a9920d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ef90855983924e36\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ef90855983924e36\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a768ecfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=2,\n",
    "    gpus=1 if torch.cuda.is_available() else 0,\n",
    "    enable_progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6289402a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type                  | Params\n",
      "--------------------------------------------------------\n",
      "0 | seq_encoder   | TransformerSeqEncoder | 55.6 K\n",
      "1 | head          | Head                  | 132   \n",
      "2 | loss          | NLLLoss               | 0     \n",
      "3 | train_metrics | ModuleDict            | 0     \n",
      "4 | valid_metrics | ModuleDict            | 0     \n",
      "5 | test_metrics  | ModuleDict            | 0     \n",
      "--------------------------------------------------------\n",
      "55.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.7 K    Total params\n",
      "0.223     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logger.version = 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bfa897d94b44bc4a99c92567b36fffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6h 38min 45s, sys: 2h 38min 26s, total: 9h 17min 11s\n",
      "Wall time: 1h 15min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f'logger.version = {trainer.logger.version}')\n",
    "trainer.fit(sup_module, sup_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "285e7114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(1.0247), 'seq_len': tensor(851.9688), 'y': tensor(1.6250), 'val_loss': tensor(1.0196), 'valid/Accuracy': tensor(0.5547), 'train/Accuracy': tensor(0.5416)}\n"
     ]
    }
   ],
   "source": [
    "# train and validation metrics\n",
    "print(trainer.logged_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "55b93bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/jovyan/lightning_logs/version_1/checkpoints/epoch=1-step=314.ckpt\n",
      "Loaded model weights from checkpoint at /home/jovyan/lightning_logs/version_1/checkpoints/epoch=1-step=314.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c28bcf9b7d4eac9aa44690f955fb36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5495714545249939     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5495714545249939    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test/Accuracy': 0.5495714545249939}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test metrics\n",
    "trainer.test(ckpt_path='best', dataloaders=sup_data.test_dataloader())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538a5c57",
   "metadata": {},
   "source": [
    "# Make predict\n",
    "\n",
    "Let's make predict to check metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "46b36509",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptls.data_load.utils import collate_feature_dict\n",
    "from ptls.frames.inference_module import InferenceModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fd672b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_dl = torch.utils.data.DataLoader(\n",
    "    dataset=dataset_test,\n",
    "    collate_fn=collate_feature_dict,\n",
    "    shuffle=False,\n",
    "    batch_size=1000,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "69fadd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_module = InferenceModule(\n",
    "    torch.nn.Sequential(\n",
    "        sup_module,\n",
    "        torch.nn.Softmax(dim=1),\n",
    "    ),\n",
    "    model_out_name='prob',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9abe09cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd3a4b57c3e74c95ba0fb0e2b5a5ba1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 157it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_predict = trainer.predict(inf_module, inference_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e959950c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = pd.concat(df_predict, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c19c6b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>target_bin</th>\n",
       "      <th>prob_0000</th>\n",
       "      <th>prob_0001</th>\n",
       "      <th>prob_0002</th>\n",
       "      <th>prob_0003</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>3769</td>\n",
       "      <td>2</td>\n",
       "      <td>0.065010</td>\n",
       "      <td>0.004084</td>\n",
       "      <td>0.922117</td>\n",
       "      <td>0.008790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>13871</td>\n",
       "      <td>2</td>\n",
       "      <td>0.262393</td>\n",
       "      <td>0.031538</td>\n",
       "      <td>0.622771</td>\n",
       "      <td>0.083299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>11754</td>\n",
       "      <td>3</td>\n",
       "      <td>0.068451</td>\n",
       "      <td>0.667012</td>\n",
       "      <td>0.005306</td>\n",
       "      <td>0.259231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>19111</td>\n",
       "      <td>3</td>\n",
       "      <td>0.099277</td>\n",
       "      <td>0.610973</td>\n",
       "      <td>0.006524</td>\n",
       "      <td>0.283227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>31272</td>\n",
       "      <td>1</td>\n",
       "      <td>0.213297</td>\n",
       "      <td>0.450815</td>\n",
       "      <td>0.043134</td>\n",
       "      <td>0.292753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>39318</td>\n",
       "      <td>2</td>\n",
       "      <td>0.045078</td>\n",
       "      <td>0.004748</td>\n",
       "      <td>0.942754</td>\n",
       "      <td>0.007420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>44799</td>\n",
       "      <td>0</td>\n",
       "      <td>0.511363</td>\n",
       "      <td>0.033735</td>\n",
       "      <td>0.281010</td>\n",
       "      <td>0.173892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>25731</td>\n",
       "      <td>0</td>\n",
       "      <td>0.501576</td>\n",
       "      <td>0.047266</td>\n",
       "      <td>0.249107</td>\n",
       "      <td>0.202051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>12658</td>\n",
       "      <td>0</td>\n",
       "      <td>0.229762</td>\n",
       "      <td>0.408421</td>\n",
       "      <td>0.107694</td>\n",
       "      <td>0.254123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>21866</td>\n",
       "      <td>2</td>\n",
       "      <td>0.371182</td>\n",
       "      <td>0.013171</td>\n",
       "      <td>0.534654</td>\n",
       "      <td>0.080994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     client_id  target_bin  prob_0000  prob_0001  prob_0002  prob_0003\n",
       "530       3769           2   0.065010   0.004084   0.922117   0.008790\n",
       "958      13871           2   0.262393   0.031538   0.622771   0.083299\n",
       "671      11754           3   0.068451   0.667012   0.005306   0.259231\n",
       "708      19111           3   0.099277   0.610973   0.006524   0.283227\n",
       "368      31272           1   0.213297   0.450815   0.043134   0.292753\n",
       "520      39318           2   0.045078   0.004748   0.942754   0.007420\n",
       "272      44799           0   0.511363   0.033735   0.281010   0.173892\n",
       "615      25731           0   0.501576   0.047266   0.249107   0.202051\n",
       "811      12658           0   0.229762   0.408421   0.107694   0.254123\n",
       "72       21866           2   0.371182   0.013171   0.534654   0.080994"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26257800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "db5e2b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 2, 2])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = df_predict[[f'prob_{i:04d}' for i in range(4)]].values.argmax(axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bddd6d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 1, ..., 1, 2, 2])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = df_predict['target_bin'].values\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ad4d074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cb10cd53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5495714285714286"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3b4df3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 667,  155,  698,  215],\n",
       "       [ 221, 1148,  101,  279],\n",
       "       [ 155,   35, 1557,   17],\n",
       "       [ 557,  501,  219,  475]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4b3c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
